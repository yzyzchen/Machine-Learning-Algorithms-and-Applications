{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e099c1c0-78c7-4c2d-840c-02ed818869f8",
   "metadata": {},
   "source": [
    "# EECS 545 (WN 2024) Homework 4: Transformers\n",
    "\n",
    "<span class=\"instruction\">Before starting the assignment, please fill in the following cell.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cca9d9-6e6e-47a5-910b-57863f66a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Enter your first and last name, e.g. \"John Doe\"                 #\n",
    "# for example                                                     #\n",
    "# __NAME__ = \"Violet Fu\"                                          #\n",
    "# __UNIQID__ = \"violetfy\"                                         #\n",
    "###################################################################\n",
    "raise NotImplementedError(\"TODO: Add your implementation here.\")\n",
    "###################################################################\n",
    "#                        END OF YOUR CODE                         #\n",
    "###################################################################\n",
    "\n",
    "print(f\"Your name and email: {__NAME__} <{__UNIQID__}@umich.edu>\")\n",
    "assert __NAME__ and __UNIQID__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc5112-a91b-4d2d-b521-ba413501a051",
   "metadata": {},
   "source": [
    "# Transformer on text generation \n",
    "In this notebook, you will test the Attention Module and the PyTorch training code you implemented in **transformer.py** and **transformer_trainer.py**. This requires running code in PyTorch. Ideally, you should run this file on <span style=\"color: violet;\">**GPU**</span>. If it is not available on your own machine, we recommand running on <span style=\"color: violet;\">**Colab**</span>. Please refer to this [instruction](https://docs.google.com/document/d/e/2PACX-1vSgRhviaU_N_ErIwytT6vJ52gxmjiBcRGDs7q80qeifOVyuRkwZYchXMFn-HU0UjXrvmGzR2fB9QsOz/pub) about how to use Colab. If you evenatually decide to run everything with **CPU**, please start early and allocate at least a few hours for section(C) as it is going to take long. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659fe37-7eea-4735-aa3f-90fcfbc02fd1",
   "metadata": {},
   "source": [
    "## Setup code\n",
    "Before getting started, we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook. Let's start by checking whether we are using Python 3.11 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d8911-13a1-4e18-bc70-9c2ce1755085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"You must use Python 3\")\n",
    "\n",
    "if sys.version_info[1] < 11:\n",
    "    print(\"Autograder will execute your code based on Python 3.11 environment. Please use Python 3.11 or higher to prevent any issues\")\n",
    "    print(\"You can create a conda environment with Python 3.11 like 'conda create --name eecs545 python=3.11'\")\n",
    "    raise Exception(\"Python 3 version is too low: {}\".format(sys.version))\n",
    "else:\n",
    "    print(\"You are good to go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd11a340-bd8a-4f85-8c43-a4e07ffee399",
   "metadata": {},
   "source": [
    "First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84798bb1-9ac6-4b72-96ed-d31c782fda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba2665-5ca0-4d12-ade8-7bda4fe31acc",
   "metadata": {},
   "source": [
    "Then, we run some setup code for this notebook: Import some useful packages and increase the default figure size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86df53-fa79-407e-993c-808a02b31c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below to install packages if they are not installed yet. \n",
    "# !pip install numpy==1.24.1 matplotlib==3.6.2 scikit-learn==1.2.0 imageio==2.25.1\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d30024-7808-485b-944f-e39c54688e19",
   "metadata": {},
   "source": [
    "Next, we need to make sure pytorch is installed. The following command will install pytorch if you haven't installed it before. Depending on your OS and GPU hardware, this may install a CPU or GPU version. If you want to use a GPU with PyTorch (which will exponentially speed up your computation time) you can follow the instructions on the pytorch [official website](https://pytorch.org/get-started/locally/). In this problem set a CPU-only pytorch is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26543ce5-b5f3-44cf-a664-059a8b159bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uncomment and run the line below to install pytorch is you haven't done so\n",
    "!pip install torch==2.2.1 torchvision==0.17.1\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d11a0-cb8f-4fc0-8fb2-b6578c229e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if CUDA is available on torch\n",
    "print('PyTorch CUDA is available?', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb99e48-9209-4ef9-9bd7-17e96e81e22b",
   "metadata": {},
   "source": [
    "To reproduce results, it is important to set seed. The function below helps to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5c5e3-6959-4a83-96d9-4af95f150b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "set_seed(12345) #set a fixed random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c38cc0-d51e-4fbe-beea-b9049c58fafd",
   "metadata": {},
   "source": [
    "### Section(A) Check your attention implementation\n",
    "Now, let's check your transformer implementation. A correct implementation should pass the assert_allclose line and does not trigger any error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb70b59-edbf-4044-b1f5-fb6c3a6306b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import MaskedAttention\n",
    "set_seed(12345)\n",
    "attention = MaskedAttention(48, 3, 3)\n",
    "inputs = [[[ 0.8852, -1.1841,  0.4406,  0.6939, -0.8548, -0.7011,  0.2941,\n",
    "           0.6334,  1.6439,  0.2185, -1.8231,  0.3305, -3.6633, -0.5477,\n",
    "          -1.5629,  1.3776, -2.3223,  1.1882, -1.0146,  0.4610, -0.6772,\n",
    "           1.0473,  0.6797, -1.3599,  0.5765,  1.3818,  1.9596,  0.2333,\n",
    "           0.4236,  1.5104,  0.5365, -1.2894,  1.0061,  0.0317,  0.9216,\n",
    "           0.8358, -0.0778,  0.2040,  0.5083, -1.4204, -0.5308,  0.5121,\n",
    "           1.4943,  1.3703,  0.4305,  1.2011, -1.8800, -0.1506],\n",
    "         [-0.1161,  1.0082,  1.1272,  1.0432, -0.5849, -1.9456, -0.5046,\n",
    "          -0.0495, -0.1723, -0.7835,  0.0706, -1.1203, -0.5606,  0.6311,\n",
    "          -0.4215, -1.4242,  0.5186,  1.2899, -1.6057, -0.7066,  0.0234,\n",
    "           0.0535, -0.1760,  2.7153, -0.3977,  0.4018,  1.7233, -0.4099,\n",
    "           0.8925, -1.6363,  0.5603,  0.8228, -0.6935,  0.5939,  0.0261,\n",
    "          -0.8228,  1.0020,  0.8776,  0.2597,  0.5770, -0.7814,  0.4137,\n",
    "          -3.1109,  1.5095, -1.3054, -0.2762, -0.2339, -0.0605],\n",
    "         [-0.9684,  0.8253,  1.1051, -0.7230,  0.3950, -0.3346, -0.0271,\n",
    "          -1.6035, -0.3299,  0.6642, -0.4004, -0.6389, -0.2243,  0.8469,\n",
    "          -1.0028, -0.2318,  1.4500,  0.1103,  1.2395,  0.2621,  1.8836,\n",
    "          -0.6182,  2.1644,  1.5504,  3.0542,  0.9740, -2.8405,  0.8848,\n",
    "           0.2762, -0.7397,  1.5389, -0.6161, -0.3589, -0.0085,  0.1275,\n",
    "          -0.2849, -0.6918, -1.7355, -1.0572, -0.4486, -0.5446,  0.8705,\n",
    "           0.8601, -0.1449,  1.4177, -0.2919,  0.7602,  0.4350]]]\n",
    "inputs = torch.tensor(inputs).float()\n",
    "attention.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = attention(inputs)\n",
    "expected_outputs = np.array([[[-0.1486,  0.1777, -0.3494, -0.2162, -0.1077,  0.0685, -1.0346,\n",
    "                              -0.6672, -0.8616, -0.3380,  0.2046, -0.0050, -0.0738,  0.1913,\n",
    "                               0.1332, -0.3641, -0.4243,  0.1188,  0.0215,  0.2370,  0.6812,\n",
    "                              -0.1018,  0.0788, -0.6371, -0.4669,  0.6068,  0.1693,  0.1214,\n",
    "                              -0.8412, -0.1185, -0.2494,  0.4053,  0.3242, -0.0280,  0.3158,\n",
    "                              -0.2219,  0.1630, -0.0745, -0.1231, -0.6197,  0.5833, -0.3247,\n",
    "                               0.3002, -0.1323, -0.4823, -0.5536, -0.1559,  0.5801],\n",
    "                             [ 0.0702,  0.1089, -0.4341, -0.0671, -0.2151, -0.0183, -0.5890,\n",
    "                              -0.6078, -0.8475, -0.4055, -0.1759, -0.0395, -0.0636,  0.2831,\n",
    "                               0.0722, -0.1965, -0.2158,  0.1390, -0.2303,  0.2821,  0.5404,\n",
    "                               0.0640,  0.1459, -0.4615, -0.3691,  0.2262,  0.1783, -0.0748,\n",
    "                              -0.6773, -0.1486, -0.0890,  0.5385,  0.0556,  0.0576,  0.1533,\n",
    "                              -0.0288,  0.0889, -0.0435, -0.1417, -0.2416,  0.4084, -0.2700,\n",
    "                               0.0975, -0.1606, -0.4313, -0.4773, -0.0866,  0.2469],\n",
    "                             [-0.1378, -0.1708, -0.2168, -0.0777, -0.0604,  0.0068, -0.6403,\n",
    "                              -0.3968, -0.3044, -0.1192, -0.4150,  0.2027,  0.0118,  0.1063,\n",
    "                              -0.1213,  0.2542,  0.0388, -0.0865, -0.2399, -0.0096,  0.3200,\n",
    "                               0.0793,  0.0022, -0.1296, -0.0470,  0.1209,  0.0395,  0.3965,\n",
    "                              -0.2515, -0.3861, -0.3169,  0.0824,  0.2049,  0.1243, -0.1657,\n",
    "                               0.0492, -0.1103,  0.1369,  0.1256, -0.4973,  0.1020, -0.1457,\n",
    "                               0.1124, -0.2355, -0.4387, -0.4518, -0.0035,  0.0864]]])\n",
    "\n",
    "np.testing.assert_allclose(outputs.cpu().numpy(), expected_outputs, atol=1e-3)\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb26a8-6f45-43f0-8589-2b095fd7aa17",
   "metadata": {},
   "source": [
    "### Section(B) Train your model to learn multiplication. \n",
    "The code base below is a math multiplication dataset for n-digit multiplication. Specifically, we are focusing on 2-digit multiplication problem in this homework, for example, for input 54x45, the expected output is 2430."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4458630-c634-44ba-b0a8-f0372b5c4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitMultiplicationDataset(Dataset):\n",
    "    def __init__(self, n, data_comb, split):\n",
    "        self.n = n # max number of digit\n",
    "        n_train = int(0.8*data_num)\n",
    "        self.data = data_comb[:n_train] if split == 'train' else data_comb[n_train:]\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return 4*self.n - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.nelement()\n",
    "\n",
    "    def digit_to_str(self, x, ndigit):\n",
    "        return f'%0{ndigit}d' % x\n",
    "\n",
    "    def str_to_digit(self, x, device):\n",
    "        factors = torch.tensor([[10**i for i in range(x.shape[-1])][::-1]]).to(device)\n",
    "        return (x * factors).sum(dim=1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.data[idx].item()\n",
    "        a, b = inputs // (10**self.n), inputs % (10**self.n)\n",
    "        c = a * b # target\n",
    "        # encode digits\n",
    "        astr = self.digit_to_str(a, self.n)\n",
    "        bstr = self.digit_to_str(b, self.n)\n",
    "        cstr = self.digit_to_str(c, 2*self.n) #2-digit numbers multiply to up to 4 digits.\n",
    "        # we ignore * symbol because we only finetune on multiplication. \n",
    "        concat_str = f'{astr}{bstr}{cstr[::-1]}'\n",
    "        concat = [int(s) for s in concat_str]\n",
    "        x = torch.tensor(concat[:-1]).long() #given the sequence 01020\n",
    "        y = torch.tensor(concat[1:]).long() #predict the next digit 10203\n",
    "        y[:self.n*2-1] = -100 #masked out input\n",
    "        return x, y\n",
    "\n",
    "# generate data\n",
    "ndigit=2\n",
    "rng = torch.Generator()\n",
    "rng.manual_seed(1337)\n",
    "data_num = (10**ndigit)**2\n",
    "data_comb = torch.randperm(data_num, generator=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58830a-c91b-4373-ae25-812acaa3f80a",
   "metadata": {},
   "source": [
    "Run the code below to train a model that learns 2-digit number multiplication!\n",
    "\n",
    "If you are worried that the training break and you lose the training progress, you can refer to [PyTorch checkpoint](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html) to save and load checkpoints while you train. Generally this will not happen for small models with short training time if you run on GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa53d8-f776-48e4-9f9f-f04f44b930b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import GPT\n",
    "from transformer_trainer import Trainer, Evaluator\n",
    "\n",
    "set_seed(12345)\n",
    "train_dataset = DigitMultiplicationDataset(ndigit, data_comb, split='train')\n",
    "test_dataset = DigitMultiplicationDataset(ndigit, data_comb, split='test')\n",
    "n_layer, n_head, embedding_dim = 4, 4, 128\n",
    "multip_model = GPT(n_layer, \n",
    "                   n_head,\n",
    "                   embedding_dim, \n",
    "                   10, # 10 possible digits\n",
    "                   train_dataset.get_block_size())\n",
    "\n",
    "learning_rate = 1e-3\n",
    "max_iters=20000 \n",
    "multip_trainer = Trainer(multip_model, train_dataset, learning_rate, max_iters=max_iters)\n",
    "multip_trainer.test_dataset = test_dataset\n",
    "multip_trainer.run('multiplication')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017b9e9-ce77-409f-9290-e64d7cf36688",
   "metadata": {},
   "source": [
    "Now let's evaluate the trained model on the held-out test dataset to see if it overfits. How does it perform? Please report the final training/testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8074f386-512d-4370-bc2a-0ad2b4df90ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(12345)\n",
    "Evaluator(test_dataset, multip_model, 'test').eval_split(multip_trainer.device, print_example=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0573b-8dde-4144-9829-a597b291aa4b",
   "metadata": {},
   "source": [
    "Now, let's plot the training loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca17093-3cf3-45f5-a7e2-3be625a8ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(multip_trainer.train_losses)\n",
    "plt.xlabel(f'Iteration (every {multip_trainer.log_interval})')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss history')\n",
    "plt.savefig('multiplication_loss.png', dpi=256)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643cb89c-91a9-4899-b9eb-4985168b5a02",
   "metadata": {},
   "source": [
    "# Section(C) Train a model to tell stories!\n",
    "Now, let's train a model to tell short stories! \n",
    "We are going to train the model on the [tiny stories](https://huggingface.co/datasets/roneneldan/TinyStories/tree/main). Please open the link, \n",
    "download the **TinyStories-train.txt** file, and put it in your **data** folder like below. \n",
    "```\n",
    "HW4 /\n",
    "--| transformer.ipynb\n",
    "--| data /\n",
    "----| TinyStories-train.txt\n",
    "----| ...\n",
    "```\n",
    "Here is one example: \n",
    "*One day, a little girl wanted to paint. She went outside, and looked around. The grass was green, and the sky was blue. It was a mild day, so it was perfect for painting.\n",
    "The little girl began to paint, and she used all the colors from her box of paints. Red, yellow, and blue. She painted on the grass, and she made a beautiful picture.\n",
    "She painted flowers and birds, and she was very proud of her work. The sun was shining, so everything looked very bright.\n",
    "When she was finished, she stood up and looked at her painting. She felt very happy, because she had made something beautiful. She knew she would always remember this mild day and the painting she made on the grass.\n",
    "After this, run the code in the cell below to load the stories.*\n",
    "\n",
    "Now let's load the dataset you download and run the cell below to convert the loaded stories to a dataset class to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab20267-cac9-4200-8371-50c98a1a940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/TinyStories-train.txt'\n",
    "unique_chars = set()\n",
    "data_len = 0\n",
    "with open(file_path, 'rb') as file:\n",
    "    while True:\n",
    "        chunk = file.read(int(1e7)) #we do this in chunk to make it compatible with limited memory\n",
    "        chunk = chunk.decode('utf-8')\n",
    "        data_len += len(chunk)\n",
    "        print(data_len)\n",
    "        if not chunk:\n",
    "            break \n",
    "        for char in chunk:\n",
    "            unique_chars.add(char)\n",
    "sorted_unique_chars = sorted(unique_chars)\n",
    "assert data_len == 1922767089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee893ca3-f763-4900-9b42-382d5b0fa478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryDataset(Dataset):\n",
    "    def __init__(self, file_path, chars, data_size, block_size):\n",
    "        self.block_size = block_size\n",
    "        self.loader = self.read_in_batches(file_path)\n",
    "        self.data_size = data_size #1922767089\n",
    "        vocab_size = len(chars)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.stoi = {char:idx for idx,char in enumerate(chars)}\n",
    "        self.itos = {idx:char for idx,char in enumerate(chars)}\n",
    "        \n",
    "    def get_block_size(self):\n",
    "        return self.block_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_size-self.block_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        seq = next(self.loader)\n",
    "        indices = [self.stoi[s] for s in seq]\n",
    "        x = torch.tensor(indices[:-1]).long()\n",
    "        y = torch.tensor(indices[1:]).long()\n",
    "        return x, y\n",
    "        \n",
    "    def read_in_batches(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            while True:\n",
    "                batch = file.read(self.block_size)\n",
    "                if not batch:\n",
    "                    file.seek(0)\n",
    "                    continue\n",
    "                yield batch\n",
    "                \n",
    "block_size = 256\n",
    "train_dataset = StoryDataset(file_path,\n",
    "                             sorted_unique_chars, \n",
    "                             data_len,\n",
    "                             block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0595f8-3c74-4002-846f-cb907049b1b4",
   "metadata": {},
   "source": [
    "**Notice**: There is NO EXTRA CODE for you to implement in this section. You can directly reuse your code that you implemented in section(A) and (B). However, the model we are going to run is larger than the one from the section(B), therefore it is going to take <span style=\"color: violet;\">**significantly longer**</span>, especially when running on CPU. Therefore, please start doing this **AS EARLY AS POSSIBLE**. \n",
    "\n",
    "Again, as training this model requires longer, it is possible that training breaks and you lose all the training progress, therefore if you are worried about this, you can refer to [PyTorch checkpoint](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html) to save and load checkpoints while you train. \n",
    "\n",
    "In early iterations, the model will not generate anything meaningful, but as you train the model for more iterations, you will gradually see some interesting stories. The stories can be **imperfect** because we are only running a small model, but it should generate real words mostly, and follow grammar rules to some extent. Don't worry if the story is longer than the maximum length(1024 chars). Feel free to run it for longer (increase max_iters) or make the model size larger if you have time and want better results, but the default setting should be good enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d26d4-1a6a-4207-b2f4-4d2f20ed379e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer import GPT\n",
    "from transformer_trainer import Trainer, Evaluator\n",
    "\n",
    "set_seed(12345)\n",
    "# torch.cuda.set_device(1) #you can ignore this line, it's to switch cuda device\n",
    "\n",
    "n_layer, n_head, embedding_dim = 8, 8, 256\n",
    "story_model = GPT(n_layer, \n",
    "                  n_head, \n",
    "                  embedding_dim, \n",
    "                  train_dataset.vocab_size, \n",
    "                  block_size)\n",
    "learning_rate = 1e-3\n",
    "max_iters=15000\n",
    "story_trainer = Trainer(story_model, train_dataset, learning_rate, batch_size=64, max_iters=max_iters)\n",
    "story_trainer.run('story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dfe4ea-ae9f-466b-9fb4-ff2605f1d244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
