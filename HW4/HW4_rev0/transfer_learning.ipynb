{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNmLmqrJAXXp"
   },
   "source": [
    "# EECS 545 (WN 2024) Homework 4: Transfer Learning\n",
    "\n",
    "<span class=\"instruction\">Before starting the assignment, please fill in the following cell.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Enter your first and last name, e.g. \"John Doe\"                 #\n",
    "# for example                                                     #\n",
    "# __NAME__ = \"Anthony Liu\"                                        #\n",
    "# __UNIQID__ = \"anthliu\"                                          #\n",
    "###################################################################\n",
    "raise NotImplementedError(\"TODO: Add your implementation here.\")\n",
    "###################################################################\n",
    "#                        END OF YOUR CODE                         #\n",
    "###################################################################\n",
    "\n",
    "print(f\"Your name and email: {__NAME__} <{__UNIQID__}@umich.edu>\")\n",
    "assert __NAME__ and __UNIQID__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hbe3wUpVAjma"
   },
   "source": [
    "# Transfer Learning\n",
    "In this notebook, you will test your transfer learning implementation from `transfer_learning.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYE9thuXn4zP"
   },
   "source": [
    "## Setup code\n",
    "Before getting started, we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook. Let's start by checking whether we are using Python 3.10 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqEfH2Rpn9J3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"You must use Python 3\")\n",
    "\n",
    "if sys.version_info[1] < 11:\n",
    "    print(\"Autograder will execute your code based on Python 3.11 environment. Please use Python 3.11 or higher to prevent any issues\")\n",
    "    print(\"You can create a conda environment with Python 3.11 like 'conda create --name eecs545 python=3.11'\")\n",
    "    raise Exception(\"Python 3 version is too low: {}\".format(sys.version))\n",
    "else:\n",
    "    print(\"You are good to go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaCqHOm9oPB3"
   },
   "source": [
    "Then, we run some setup code for this notebook: Import some useful packages and increase the default figure size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "oCaNVx6JoWid",
    "outputId": "2133e4c6-8a6e-4ea3-dd97-23ad471ba2b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install required libraries\n",
    "# !pip install numpy==1.24.1 matplotlib==3.6.2 scikit-learn==1.2.0\n",
    "\n",
    "# import libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set figure size\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to make sure pytorch is installed. The following command will install pytorch if you haven't installed it before. Depending on your OS and GPU hardware, this may install a CPU or GPU version. If you want to use a GPU with PyTorch (which will exponentially speed up your computation time) you can follow the instructions on the pytorch [official website](https://pytorch.org/get-started/locally/). In this problem set a CPU-only pytorch is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uncomment and run the line below to install pytorch is you haven't done so\n",
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# check if CUDA is available on torch\n",
    "print('PyTorch CUDA is available?', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3EvIZ0uAOVN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html, HTML\n",
    "\n",
    "display_html(HTML('''\n",
    "<style type=\"text/css\">\n",
    "  .instruction { background-color: yellow; font-weight:bold; padding: 3px; }\n",
    "</style>\n",
    "'''));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following cell allow us to import from `transfer_learning.py`. If it works correctly, it should print the message:\n",
    "```Hello from transfer_learning.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transfer_learning import hello\n",
    "hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "We'll be doing some transfer learning on [hymenopteras](https://en.wikipedia.org/wiki/Hymenoptera). (Warning, lots of bugs!)\n",
    "\n",
    "The dataset can be downloaded through [this link](https://drive.google.com/file/d/1cGz3dhKMv1DFeRMCjBpRLyCQuR7HP_vd/view?usp=sharing) (45Mb) and unzip the folder into the data directory.\n",
    "\n",
    "```\n",
    "HW4 /\n",
    "--| transfer_learning.ipynb\n",
    "--| data /\n",
    "----| hymenoptera_data /\n",
    "------| train /\n",
    "------| ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load data from disk\n",
    "data_dir = './data/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x))\n",
    "                  for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize grid\n",
    "def make_grid(ims, h, w, captions=None):\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if ims[i*w + j] is None:\n",
    "                continue\n",
    "            plt.subplot(h, w, i*w + j + 1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(ims[i*w + j])\n",
    "            if captions is not None and captions[i*w + j] is not None:\n",
    "                plt.title(captions[i*w + j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample images from image_datasets\n",
    "sample_size = 25\n",
    "rng = np.random.default_rng(545)\n",
    "idxs = {x: rng.choice(len(image_datasets[x]), sample_size, replace=False)\n",
    "        for x in ['train', 'val']}\n",
    "samples = {x: [image_datasets[x][i][0] for i in idxs[x]]\n",
    "           for x in ['train', 'val']}\n",
    "sample_classes = {x: [image_datasets[x].classes[image_datasets[x][i][1]] for i in idxs[x]]\n",
    "                  for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.suptitle('Train samples')\n",
    "make_grid(samples['train'], sample_size // 5, 5, sample_classes['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.suptitle('Validation samples')\n",
    "make_grid(samples['val'], sample_size // 5, 5, sample_classes['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing images\n",
    "\n",
    "Before we can start training with these images, we need to make sure\n",
    "1. The image sizes are correct (224 x 224) images\n",
    "2. The images are normalized to the mean and standard deviation in each channel. Normalization will almost always improve NN performance by removing scaling patterns in the input data.\n",
    "In addition, since we are transfer learning on an *ImageNet model*, we need to apply the same normalization as applied in the original model. This is: normalized = (image - mu) / std, where mu = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n",
    "These were are the mean and standard deviations of each channel in the ImageNet dataset.\n",
    "\n",
    "In addtion, we can apply some image augmentations to the training data. E.g. we can randomly crop and randomly flip the training images. This way, we can artificially learn on more training data and improve performance!\n",
    "\n",
    "We can visualize some of these transformations as follows, for which pytorch gives some convenient functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im = image_datasets['train'][7][0]\n",
    "grid = [\n",
    "    im,\n",
    "    transforms.CenterCrop(224)(im),\n",
    "    transforms.RandomResizedCrop(224)(im),\n",
    "    transforms.RandomResizedCrop(224)(im),\n",
    "    transforms.RandomHorizontalFlip()(im),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(transforms.ToTensor()(im)).permute(1, 2, 0),\n",
    "]\n",
    "caps = [\n",
    "    'original',\n",
    "    'Center crop',\n",
    "    'Random crop',\n",
    "    'Random crop',\n",
    "    'Random flip',\n",
    "    'Normalized (clipped)',\n",
    "]\n",
    "make_grid(grid, h=2, w=3, captions=caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together\n",
    "\n",
    "<span class=\"instruction\">Complete the missing code segments in `transfer_learning.py` marked by the TODOs.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load data from disk\n",
    "data_dir = './data/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "               shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the device to CUDA if it's available, otherwise we'll use CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune the pre-trained model\n",
    "\n",
    "*Warning:* If you are training on CPU, this may take some time (up to a few hours).\n",
    "To give you an idea of whether your code is working or not, our instructor solution gets around ~65%, ~75% and 80% after 1, 2, and 3 epochs.\n",
    "These numbers are not exact and may fluctuate due to randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transfer_learning import finetune\n",
    "\n",
    "NUM_EPOCHS = 5# Feel free to train more epochs if you have time\n",
    "model_ft = finetune(device, dataloaders, dataset_sizes, class_names, num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "unnormalize = lambda t: t.permute(1, 2, 0) * std + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transfer_learning import visualize_model\n",
    "\n",
    "num_images = 6\n",
    "tensors, captions = visualize_model(device, dataloaders, model_ft, class_names, num_images=num_images)\n",
    "images = [unnormalize(t) for t in tensors]\n",
    "plt.suptitle('Finetuned Model Predictions')\n",
    "make_grid(images, h=num_images // 3, w=3, captions=captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the parameters in pre-trained model and train the final fc layer\n",
    "*Warning:* If you are training on CPU, this may take some time (up to a few hours).\n",
    "To give you an idea of whether your code is working or not, our instructor solution gets around ~65%, ~75% and 80% after 1, 2, and 3 epochs.\n",
    "These numbers are not exact and may fluctuate due to randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transfer_learning import freeze\n",
    "\n",
    "NUM_EPOCHS = 5# Feel free to train with more epochs if you have time\n",
    "model_conv = freeze(device, dataloaders, dataset_sizes, class_names, num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_images = 6\n",
    "tensors, captions = visualize_model(device, dataloaders, model_conv, class_names, num_images=num_images)\n",
    "images = [unnormalize(t) for t in tensors]\n",
    "plt.suptitle('Frozen Model Predictions')\n",
    "make_grid(images, h=num_images // 3, w=3, captions=captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did you do? Report the accuracy on the validation dataset for both the finetuned and frozen scenarios in your final report."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eYE9thuXn4zP",
    "CdowvtJen-IP",
    "KtMy3qeipNK3",
    "Hbe3wUpVAjma",
    "lJqim3P1qZgv",
    "ZLdCF3B-AOVT",
    "7XNJ3ydEAOVW",
    "vExP-7n3AOVa",
    "LjAUalCBAOVd",
    "8cPIajWNAOVg",
    "_CsYAv3uAOVi",
    "ixxgq5RKAOVl",
    "OlVbXxmPNzPY",
    "rDNZ8ZAnN7hj",
    "QpSrK3olUfOZ",
    "3zFWkxebWXtu",
    "mVCEro4FAOVq",
    "UG56gKWsAOVv",
    "37R_J2uMP3d-"
   ],
   "name": "two_layer_net.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
