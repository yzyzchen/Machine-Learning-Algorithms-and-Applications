{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNmLmqrJAXXp"
   },
   "source": [
    "# EECS 545 (WN 2024) Homework 4: Convolutional Neural Networks\n",
    "\n",
    "<span class=\"instruction\">Before starting the assignment, please fill in the following cell.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Enter your first and last name, e.g. \"John Doe\"                 #\n",
    "# for example                                                     #\n",
    "# __NAME__ = \"Anthony Liu\"                                        #\n",
    "# __UNIQID__ = \"anthliu\"                                          #\n",
    "###################################################################\n",
    "raise NotImplementedError(\"TODO: Add your implementation here.\")\n",
    "###################################################################\n",
    "#                        END OF YOUR CODE                         #\n",
    "###################################################################\n",
    "\n",
    "print(f\"Your name and email: {__NAME__} <{__UNIQID__}@umich.edu>\")\n",
    "assert __NAME__ and __UNIQID__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hbe3wUpVAjma"
   },
   "source": [
    "# CNNs and MNIST\n",
    "In this notebook, you will test your convolution layer implementation from `layers.py` and then test your CNN implementation from `cnn.py` on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYE9thuXn4zP"
   },
   "source": [
    "## Setup code\n",
    "Before getting started, we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook. Let's start by checking whether we are using Python 3.11 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqEfH2Rpn9J3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"You must use Python 3\")\n",
    "\n",
    "if sys.version_info[1] < 11:\n",
    "    print(\"Autograder will execute your code based on Python 3.11 environment. Please use Python 3.11 or higher to prevent any issues\")\n",
    "    print(\"You can create a conda environment with Python 3.11 like 'conda create --name eecs545 python=3.11'\")\n",
    "    raise Exception(\"Python 3 version is too low: {}\".format(sys.version))\n",
    "else:\n",
    "    print(\"You are good to go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaCqHOm9oPB3"
   },
   "source": [
    "Then, we run some setup code for this notebook: Import some useful packages and increase the default figure size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "oCaNVx6JoWid",
    "outputId": "2133e4c6-8a6e-4ea3-dd97-23ad471ba2b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install required libraries\n",
    "# !pip install numpy==1.24.1 matplotlib==3.6.2 scikit-learn==1.2.0 imageio==2.25.1\n",
    "\n",
    "# import libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set figure size\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3EvIZ0uAOVN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html, HTML\n",
    "\n",
    "display_html(HTML('''\n",
    "<style type=\"text/css\">\n",
    "  .instruction { background-color: yellow; font-weight:bold; padding: 3px; }\n",
    "</style>\n",
    "'''));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following cell allow us to import from `cnn_layers.py` and `cnn.py`. If it works correctly, it should print the message:\n",
    "```Hello from cnn_layers.py``` and ```Hello from cnn.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cnn_layers import hello\n",
    "from cnn import hello as hello2\n",
    "hello()\n",
    "hello2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Layer\n",
    "Let's test your `conv_forward` and `conv_backward` implementations on some toy data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# toy dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_toy_data(dim, fdim):\n",
    "    # Generate data\n",
    "    coords_x, coords_y = np.meshgrid(np.linspace(-1, 1, num=dim), np.linspace(-1, 1, num=dim))\n",
    "    X = np.zeros((1, 3, dim, dim))# N, C, H, W\n",
    "    X[:, 0] = np.sin(10 * (coords_x**2 + coords_y**2))**2\n",
    "    X[:, 1] = np.clip(np.sin(5 * coords_x) * np.cos(5 * coords_y), 0, 1)\n",
    "    X[:, 2] = np.clip(np.sin(2 * coords_x - 1) * np.cos(2 * coords_y - 1) * 2, 0, 1)\n",
    "\n",
    "    # Create filter\n",
    "    K = np.zeros((3, 3, fdim, fdim))\n",
    "    K[0, 0] = np.eye(fdim) / fdim# diagonals on the red channel\n",
    "    K[1, 1] = (1 / fdim)**2# blur on the green channel\n",
    "    K[2, 2, 2, 2] = 0.5# dim on the blue channel\n",
    "    \n",
    "    return X, K\n",
    "\n",
    "# visualize toy data:\n",
    "def visualize(**kwargs):\n",
    "    n_plots = len(kwargs)\n",
    "    for i, (title, im_array) in enumerate(kwargs.items()):\n",
    "        im = im_array[0].transpose(1, 2, 0)\n",
    "        plt.subplot(1, n_plots, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(im)\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLdCF3B-AOVT"
   },
   "source": [
    "### Forward pass with a toy dataset\n",
    "\n",
    "<span class=\"instruction\">Please complete the forward pass code in `conv_forward` of `layers.py`</span>.\n",
    "\n",
    "First, we'll visualize some convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cnn_layers import conv_forward\n",
    "\n",
    "dim, filter_dim = 42, 7\n",
    "X, K = gen_toy_data(dim, filter_dim)\n",
    "# Convolute!\n",
    "Y, _ = conv_forward(X, K)\n",
    "assert Y.shape == (1, 3, dim - filter_dim + 1, dim - filter_dim + 1), 'conv_forward needs to output the right shape'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing toy dataset filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(filter1=K[:1]*5, filter2=K[1:2]*5, filter3=K[2:3]*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After applying filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(original=X, filter1=Y[:,:1], filter2=Y[:,1:2], filter3=Y[:,2:3], rgb_result=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization above should show an image of the data `X` and the resulting image after we applied `conv_forward` with filter `K`. If you've implemented it correctly, you should see the effects of a diagonal detector, a blur filter, and a dimming filter.\n",
    "\n",
    "Next, let's check the correct output. The distance gap between your output and the answer should be smaller than 1e-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gradient_check import rel_error\n",
    "from cnn_layers import conv_forward\n",
    "\n",
    "rng = np.random.default_rng(545)\n",
    "X_small = rng.standard_normal((2, 5, 7, 7))\n",
    "K_small = rng.standard_normal((3, 5, 5, 5))\n",
    "out, _ = conv_forward(X_small, K_small)\n",
    "correct_out = np.array([[[[ -3.34842932, -11.24497879, -17.38198515],\n",
    "         [-16.15896725,   7.72160921,  -4.15308656],\n",
    "         [-14.15831022,   4.10279395,  13.77403336]],\n",
    "\n",
    "        [[ 16.62204065,  -7.75246004,  11.79562067],\n",
    "         [ 14.743906  ,  19.39098536,   5.61990191],\n",
    "         [  5.20928401,   6.58039498,  -0.83129394]],\n",
    "\n",
    "        [[  5.33574113,  -4.44273441,  -7.39770074],\n",
    "         [-29.1247239 , -16.20540086,   2.7399245 ],\n",
    "         [  1.50572319, -11.91123209,  11.04276442]]],\n",
    "\n",
    "\n",
    "       [[[ 15.33280328,   8.01117459,  -1.50598594],\n",
    "         [ 11.75451706,  -2.36205181, -10.45831398],\n",
    "         [ -0.59063047,  14.84211664, -13.20034552]],\n",
    "\n",
    "        [[ -6.51979022,  16.46156252,   7.78735469],\n",
    "         [  2.73587298, -13.21628187, -28.46179666],\n",
    "         [ 18.35279877,  -6.91822886,  14.98855234]],\n",
    "\n",
    "        [[  5.85132249, -10.14699364,  -8.81940002],\n",
    "         [ -5.72420267, -10.56289559,  -8.27292934],\n",
    "         [ 13.06061067,  -9.34632771,  24.01649138]]]])\n",
    "# Compare your output with ours. The error might be less than 1e-7.\n",
    "# As long as your error is small enough, your implementation should pass this test.\n",
    "print('Testing conv_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))\n",
    "print()\n",
    "np.testing.assert_allclose(out, correct_out, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gradient_check import rel_error, eval_numerical_gradient_array\n",
    "from cnn_layers import conv_forward, conv_backward\n",
    "\n",
    "rng = np.random.default_rng(545)\n",
    "x = rng.standard_normal((2, 5, 7, 7))\n",
    "k = rng.standard_normal((3, 5, 5, 5))\n",
    "dout = rng.standard_normal((2, 3, 3, 3))\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_forward(x, k)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda k: conv_forward(x, k)[0], k, dout)\n",
    "\n",
    "_, cache = conv_forward(x, k)\n",
    "dx, dw = conv_backward(dout, cache)\n",
    "# The error should be around 1e-7\n",
    "print('\\nTesting conv_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print()\n",
    "\n",
    "np.testing.assert_allclose(dx, dx_num, atol=1e-7)\n",
    "np.testing.assert_allclose(dw, dw_num, atol=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Pooling Layer\n",
    "\n",
    "The forward and backward passes of `max_pool_forward` and `max_pool_backward` implementations have been implemented for you.\n",
    "Let's visualize and check the instructor solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cnn_layers import max_pool_forward\n",
    "\n",
    "dim, filter_dim = 42, 7\n",
    "X, _ = gen_toy_data(dim, filter_dim)\n",
    "# Max Pool!\n",
    "Y, _ = max_pool_forward(X, {'pool_height': 3, 'pool_width': 3, 'stride': 2})\n",
    "assert Y.shape == (1, 3, 20, 20), 'max_pool_forward needs to output the right shape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(before=X, pooled=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check for the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gradient_check import rel_error\n",
    "from cnn_layers import max_pool_forward\n",
    "\n",
    "X_small, _ = gen_toy_data(7, 3)\n",
    "out, _ = max_pool_forward(X_small, {'pool_height': 3, 'pool_width': 3, 'stride': 2})\n",
    "correct_out = np.array([[[[0.98671053, 0.98671053, 0.98671053],\n",
    "         [0.98671053, 0.80316046, 0.98671053],\n",
    "         [0.98671053, 0.98671053, 0.98671053]],\n",
    "\n",
    "        [[0.97716612, 0.97716612, 0.94135103],\n",
    "         [0.95892427, 0.99540796, 0.99540796],\n",
    "         [0.97716612, 0.97716612, 0.94135103]],\n",
    "\n",
    "        [[1.        , 1.        , 0.64784059],\n",
    "         [0.19056796, 0.19056796, 1.        ],\n",
    "         [0.        , 0.        , 1.        ]]]])\n",
    "# Compare your output with ours. The error might be less than 1e-7.\n",
    "# As long as your error is small enough, your implementation should pass this test.\n",
    "print('Testing max_pool_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))\n",
    "print()\n",
    "np.testing.assert_allclose(out, correct_out, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XNJ3ydEAOVW"
   },
   "source": [
    "### Backward pass\n",
    "Next we'll test the instructor implementation using numeric gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gradient_check import rel_error, eval_numerical_gradient_array\n",
    "from cnn_layers import max_pool_forward, max_pool_backward\n",
    "\n",
    "rng = np.random.default_rng(545)\n",
    "x = rng.standard_normal((3, 2, 7, 7))\n",
    "pool_param = {\n",
    "    'pool_height': 3,\n",
    "    'pool_width': 3,\n",
    "    'stride': 2\n",
    "}\n",
    "dout = rng.standard_normal((3, 2, 3, 3))\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: max_pool_forward(x, pool_param)[0], x, dout)\n",
    "\n",
    "_, cache = max_pool_forward(x, pool_param)\n",
    "dx = max_pool_backward(dout, cache)\n",
    "# The error should be around 1e-9\n",
    "print('\\nTesting conv_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print()\n",
    "\n",
    "np.testing.assert_allclose(dx, dx_num, atol=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "As we have all components, <span class=\"instruction\">now we would like to implement the `ConvNet` class in `cnn.py'.</span> Read through it to make sure you understand the API. You can run the cell below to test your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization Test\n",
    "Some checks to make sure `ConvNet` is initialized correctly. Hint: Make sure the shape for W3 layer is calculated correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_check import rel_error, eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cnn import ConvNet\n",
    "\n",
    "rng = np.random.default_rng(545)\n",
    "N, C, H, W, K = 3, 3, 23, 23, 7\n",
    "num_filters_1, num_filters_2, filter_size, hidden_dim = 3, 4, 4, 17\n",
    "X = rng.standard_normal((N, C, H, W))\n",
    "y = rng.integers(K, size=N)\n",
    "\n",
    "model = ConvNet(input_dim=(C, H, W), num_filters_1=num_filters_1, num_filters_2=num_filters_2, filter_size=filter_size, hidden_dim=hidden_dim, num_classes=K)\n",
    "\n",
    "print('Testing initialization... ')\n",
    "_W1 = model.params['W1']\n",
    "_W2 = model.params['W2']\n",
    "_W3 = model.params['W3']\n",
    "_b3 = model.params['b3']\n",
    "_W4 = model.params['W4']\n",
    "_b4 = model.params['b4']\n",
    "assert _W1.shape == (3, 3, 4, 4), 'W1 shape incorrect'\n",
    "assert _W2.shape == (4, 3, 4, 4), 'W2 shape incorrect'\n",
    "assert _W3.shape == (36, 17), 'W3 shape incorrect'\n",
    "assert _b3.shape == (17,), 'b3 shape incorrect'\n",
    "\n",
    "assert -0.145 < _W1.min() < _W1.max() < 0.145, 'W1 initialization range is incorrect'\n",
    "assert -0.145 < _W2.min() < _W2.max() < 0.145, 'W2 initialization range is incorrect'\n",
    "assert -0.167 < _W3.min() < _W3.max() < 0.167, 'W2 initialization range is incorrect'\n",
    "print('Passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward and Backward correctness\n",
    "\n",
    "We will test the `ConvNet.loss` function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_check import rel_error, eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cnn import ConvNet\n",
    "\n",
    "rng = np.random.default_rng(545)\n",
    "N, C, H, W, K = 3, 3, 12, 12, 7\n",
    "num_filters_1, num_filters_2, filter_size, hidden_dim = 3, 3, 3, 10\n",
    "X = rng.standard_normal((N, C, H, W))\n",
    "y = rng.integers(K, size=N)\n",
    "\n",
    "model = ConvNet(input_dim=(C, H, W), num_filters_1=num_filters_1, num_filters_2=num_filters_2, filter_size=filter_size, hidden_dim=hidden_dim, num_classes=K)\n",
    "\n",
    "reinit_like = lambda v, lb, ub: np.linspace(lb, ub, num=np.product(v.shape)).reshape(*v.shape)\n",
    "model.params['W1'] = reinit_like(model.params['W1'], -0.7, 0.3)\n",
    "model.params['W2'] = reinit_like(model.params['W2'], -0.3, 0.4)\n",
    "model.params['W3'] = reinit_like(model.params['W3'], -0.3, 0.4)\n",
    "model.params['b3'] = reinit_like(model.params['b3'], -0.9, 0.1)\n",
    "model.params['W4'] = reinit_like(model.params['W4'], -0.3, 0.4)\n",
    "model.params['b4'] = reinit_like(model.params['b4'], -0.9, 0.1)\n",
    "\n",
    "scores = model.loss(X)\n",
    "correct_scores = np.array([[1.6207142 , 2.01765557, 2.41459693, 2.81153829, 3.20847965,\n",
    "        3.60542102, 4.00236238],\n",
    "       [2.14212509, 2.61687778, 3.09163046, 3.56638314, 4.04113582,\n",
    "        4.51588851, 4.99064119],\n",
    "       [1.4395262 , 1.80835977, 2.17719335, 2.54602692, 2.91486049,\n",
    "        3.28369406, 3.65252763]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "\n",
    "# relative error should be less than 1e-7\n",
    "for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cPIajWNAOVg",
    "tags": []
   },
   "source": [
    "## Let's test our model with a dataset: CIFAR-10\n",
    "You tested a two-layer-net on the MNIST dataset in HW3. For HW4, we will test on a slightly more challenging dataset: CIFAR10. CIFAR10 (along with MNIST) is a commonly used dataset for image processing systems. Given its simplicity, it is often used for sanity tests and toy implementations.\n",
    "CIFAR10 has 10 classes (hence the name CIFAR**10**): `('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')`.\n",
    "CIFAR10 is more challenging than MNIST because it also includes color, and its classes are more difficult to distinguish than digits.\n",
    "\n",
    "You will test your implementation on this dataset. Optionally, you can also test your implementation on MNIST (and see if your implementation beats the two-layer-net). However, please submit the results from the **cifar-10** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will install PyTorch and PyTorchVision to use their CIFAR-10 dataset loader. (You will use PyTorch later in the transfer learning problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set this to 'cifar' or 'mnist'\n",
    "DATASET = 'cifar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from image_utils import process_mnist, process_cifar\n",
    "if DATASET == 'cifar':\n",
    "    loader = process_cifar\n",
    "elif DATASET == 'mnist':\n",
    "    loader = process_mnist\n",
    "else:\n",
    "    raise ValueError\n",
    "q2_data = loader('data', visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjAUalCBAOVd"
   },
   "source": [
    "### Train the network\n",
    "Let's train our CNN network! You may want to run this while doing something else. The instructor solution takes around an hour to complete 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import solver\n",
    "from cnn import ConvNet\n",
    "\n",
    "C, H, W = q2_data['X_train'][0].shape\n",
    "K = 10\n",
    "num_filters_1, num_filters_2, filter_size, hidden_dim = 6, 16, 5, 100\n",
    "num_epochs = 3# you may train for more epochs if you have time, but 3 is sufficient\n",
    "\n",
    "model = ConvNet(input_dim=(C, H, W), num_filters_1=num_filters_1, num_filters_2=num_filters_2, filter_size=filter_size, hidden_dim=hidden_dim, num_classes=K)\n",
    "\n",
    "# the update rule of 'adam' can be used to replace 'sgd' if it is helpful.\n",
    "s = solver.Solver(model, q2_data,\n",
    "                   update_rule='sgd',\n",
    "                   optim_config={'learning_rate': 1e-3, 'momentum': 0.9},\n",
    "                   lr_decay=0.95,\n",
    "                   num_epochs=num_epochs, batch_size=25,\n",
    "                   print_every=200)\n",
    "s.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the loss function and the accuracies on the training and validation sets during optimization. <span class=\"instruction\">Please report 'cnn.png' file in your **writeup**.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(s.loss_history, '.')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(s.train_acc_history, '-o', label='train')\n",
    "plt.plot(s.val_acc_history, '-x', label='val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(14, 6)\n",
    "\n",
    "plt.savefig('cnn.png', dpi=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to check the performance over the testset. (Our best model on CIFAR-10 and MNIST get around 43% and 98% test-set accuracy -- did you beat us?) <span class=\"instruction\">Please report your test accuracy in your **writeup**</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = s.check_accuracy(X=np.array(q2_data['X_test'], np.float32), y=q2_data['y_test'])\n",
    "print('Test accuracy: {:.2f}%'.format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Extra) Visualizing the learned kernels\n",
    "\n",
    "Now that we have a trained model, we can check what kernels the model has learned. If it follows what we've seen in lecture, we should see many edge detectors in the convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from image_utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learned_filters = model.params['W1'].copy().transpose(0, 2, 3, 1)\n",
    "ub, lb = learned_filters.max(), learned_filters.min()\n",
    "learned_filters = (learned_filters - lb) / (ub - lb + 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Learned filters in W1')\n",
    "#make_grid(learned_filters.squeeze(1), 4, 8)\n",
    "plt.imshow(make_grid(learned_filters, 3, padding=2))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learned_filters_2 = model.params['W2'].copy().transpose(0, 2, 3, 1)\n",
    "# Filters in W2 have 6 channels, can't visualize, so we split the 16 filters into 32.\n",
    "learned_filters_2 = learned_filters_2.reshape(2 * learned_filters_2.shape[0], learned_filters_2.shape[1], learned_filters_2.shape[2], -1)\n",
    "ub, lb = learned_filters_2.max(), learned_filters_2.min()\n",
    "learned_filters_2 = (learned_filters_2 - lb) / (ub - lb + 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Learned filters in W2')\n",
    "#make_grid(learned_filters.squeeze(1), 4, 8)\n",
    "plt.imshow(make_grid(learned_filters_2, 8, padding=2))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see? When training with 6 and 16 filters in W1 and W2 the filters can be difficult to interpret in the instructor solution."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eYE9thuXn4zP",
    "CdowvtJen-IP",
    "KtMy3qeipNK3",
    "Hbe3wUpVAjma",
    "lJqim3P1qZgv",
    "ZLdCF3B-AOVT",
    "7XNJ3ydEAOVW",
    "vExP-7n3AOVa",
    "LjAUalCBAOVd",
    "8cPIajWNAOVg",
    "_CsYAv3uAOVi",
    "ixxgq5RKAOVl",
    "OlVbXxmPNzPY",
    "rDNZ8ZAnN7hj",
    "QpSrK3olUfOZ",
    "3zFWkxebWXtu",
    "mVCEro4FAOVq",
    "UG56gKWsAOVv",
    "37R_J2uMP3d-"
   ],
   "name": "two_layer_net.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
