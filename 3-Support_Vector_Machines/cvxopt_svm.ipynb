{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5aeee1-2103-4fb5-a2f2-84991484968b",
   "metadata": {},
   "source": [
    "# EECS 545 (WN 2023) Homework 3 Q4: SVMs with Convex Optimization\n",
    "\n",
    "<span class=\"instruction\">Before starting the assignment, please fill in the following cell.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081da19b-850d-4bb0-9bde-c4344f48ffcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Enter your first and last name, e.g. \"John Doe\"                 #\n",
    "# for example                                                     #\n",
    "# __NAME__ = \"Anthony Liu\"                                        #\n",
    "# __UNIQID__ = \"anthliu\"                                          #\n",
    "###################################################################\n",
    "raise NotImplementedError(\"TODO: Add your implementation here.\")\n",
    "###################################################################\n",
    "#                        END OF YOUR CODE                         #\n",
    "###################################################################\n",
    "\n",
    "print(f\"Your name and email: {__NAME__} <{__UNIQID__}@umich.edu>\")\n",
    "assert __NAME__ and __UNIQID__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5b473-5ec6-466d-a466-b0b077a8f3cc",
   "metadata": {},
   "source": [
    "# SVMs\n",
    "\n",
    "## Scikit-learn\n",
    "In this notebook we will show you how to use Scikit-learn to train an SVM with various kernels to classify some toy datasets. We will visualize the decision boundaries and support vectors of the trained SVMs using the code included below.\n",
    "\n",
    "## Solving SVMs using convex optimizers\n",
    "There are many general purpose convex optimizers. `CVXOPT` is one such popular software package for python. As we have seen in lecture, training an SVM is a convex optimization problem, and can be solved using `CVXOPT`. This notebook will guide you on how to solve SVMs with `CVXOPT`. You will also get to compare the CVXOPT SVM with the Scikit-learn SVM.\n",
    "\n",
    "After implementing, please include the generated figures in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2e071-6a48-44de-9012-d2e8b3cfe8b0",
   "metadata": {},
   "source": [
    "## Setup code\n",
    "Before getting started, we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook. Let's start by checking whether we are using Python 3.11 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc298ee-8ca7-498b-a9ea-4bff37e2625b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"You must use Python 3\")\n",
    "\n",
    "if sys.version_info[1] < 11:\n",
    "    print(\"Autograder will execute your code based on Python 3.11 environment. Please use Python 3.11 or higher to prevent any issues\")\n",
    "    print(\"You can create a conda environment with Python 3.11 like 'conda create --name eecs545 python=3.11'\")\n",
    "    raise Exception(\"Python 3 version is too low: {}\".format(sys.version))\n",
    "else:\n",
    "    print(\"You are good to go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f7473e-f6f6-4103-a2db-6f6bac0a118e",
   "metadata": {},
   "source": [
    "First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfbe411-7f01-4bd1-96de-f84a51ce9ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c1483-542b-4a98-a5e1-5d87490f966d",
   "metadata": {},
   "source": [
    "Then, we run some setup code for this notebook: Increase the default figure size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164d739-c8ed-4257-b9cf-9d11fda63d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html, HTML\n",
    "\n",
    "display_html(HTML('''\n",
    "<style type=\"text/css\">\n",
    "  .instruction { background-color: yellow; font-weight:bold; padding: 3px; }\n",
    "</style>\n",
    "'''));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb67a55b-7773-46b7-8d27-3694ecb8c655",
   "metadata": {},
   "source": [
    "## Loading the Toy Data from SciKit Learn\n",
    "\n",
    "The toy data and visualization code has been modified and adapted from [this example](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#classifier-comparison).\n",
    "\n",
    "```\n",
    "Code source: Gaël Varoquaux\n",
    "             Andreas Müller\n",
    "Modified for documentation by Jaques Grobler\n",
    "License: BSD 3 clause\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# make linearly separable dataset\n",
    "X, y = make_classification(\n",
    "    n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n",
    ")\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "# make xor dataset\n",
    "z = rng.binomial(1, 0.5, size=(100, 2)).astype(np.bool_)\n",
    "y = np.logical_xor(z[:, 0], z[:, 1]).astype(np.int_)\n",
    "X = rng.normal(loc=z, scale=0.2)\n",
    "xor_ds = (X, y)\n",
    "\n",
    "full_datasets = [\n",
    "    make_moons(noise=0.3, random_state=0),\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "    linearly_separable,\n",
    "    xor_ds,\n",
    "]\n",
    "\n",
    "datasets = []\n",
    "for ds in full_datasets:\n",
    "    X, y = ds\n",
    "    X = (X - X.mean(0)) / X.std(0)# normalize input\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=42\n",
    "    )\n",
    "    datasets.append({\n",
    "        'X': X,\n",
    "        'y': y,\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324df1d-b2fc-427c-9c47-6ca6f9bd6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "\n",
    "# Plot the datasets first\n",
    "figure = plt.figure(figsize=(12, 3))\n",
    "figure.suptitle('Input datasets')\n",
    "for i, ds in enumerate(datasets):\n",
    "    ax = plt.subplot(1, len(datasets), i+1)\n",
    "    # Plot the training points\n",
    "    ax.scatter(ds['X_train'][:, 0], ds['X_train'][:, 1], c=ds['y_train'], cmap=cm_bright, edgecolors=\"k\")\n",
    "    # Plot the testing points\n",
    "    ax.scatter(\n",
    "        ds['X_test'][:, 0], ds['X_test'][:, 1], c=ds['y_test'], cmap=cm_bright, alpha=0.5, edgecolors=\"k\"\n",
    "    )\n",
    "    x_min, x_max = ds['X'][:, 0].min() - 0.5, ds['X'][:, 0].max() + 0.5\n",
    "    y_min, y_max = ds['X'][:, 1].min() - 0.5, ds['X'][:, 1].max() + 0.5\n",
    "\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea508bc-7104-437f-bdbc-eb8858c160bd",
   "metadata": {},
   "source": [
    "## Training SVM\n",
    "\n",
    "First of all, we want to train a SVM classifier with [sklearn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC).\n",
    "\n",
    "We'll train an SVM for each of the following kernels: linear, 3rd degree polynomial, and rbf (gaussian kernel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3af43c-bc55-4c6d-9399-50802d68ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = ['linear', 'poly', 'sigmoid', 'rbf']\n",
    "models = [[SVC(kernel=k).fit(ds['X_train'], ds['y_train']) for k in kernels] for ds in datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f69e2-e02c-4295-b8d0-6a1f8723625c",
   "metadata": {},
   "source": [
    "## Test SVM\n",
    "\n",
    "Next, we want to test the performance of pretrained SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8ca8b-ff70-4149-9e34-94c8e0f44dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "table = []\n",
    "for i, ds in enumerate(datasets):\n",
    "    row = []\n",
    "    for j, ker in enumerate(kernels):\n",
    "        accuracy = models[i][j].score(ds['X_test'], ds['y_test'])\n",
    "        row.append(accuracy)\n",
    "    table.append(row)\n",
    "\n",
    "header = '|  |' + ' | '.join(k for k in kernels) + ' |\\n'\n",
    "header += '|' + '--|'*(len(kernels)+1) + '\\n'\n",
    "rows = '\\n'.join(\n",
    "    f'| dataset {i} | ' + ' | '.join(f'{table[i][j]*100:.2f}' for j in range(len(kernels))) + ' |'\n",
    "    for i in range(len(datasets))\n",
    ")\n",
    "md('## Sklearn SVM performance\\n' + header + rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3b49db-066d-4b21-b562-6039f3bc9d03",
   "metadata": {},
   "source": [
    "## Visualizing SVM decision boundaries and support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa64c01-719a-48da-90eb-8b9ee2305e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "\n",
    "def vis_decision_boundaries(datasets, kernels, models, show_support=False):\n",
    "    figure = plt.figure(figsize=(len(datasets)*5, (len(kernels)+1)*3))\n",
    "    for i, ds in enumerate(datasets):\n",
    "        # Plot the datasets first\n",
    "        ax = plt.subplot(len(datasets), len(kernels)+1, i*(len(kernels)+1)+1)\n",
    "        if i == 0:\n",
    "            ax.set_title('Input data')\n",
    "        # Plot the training points\n",
    "        ax.scatter(ds['X_train'][:, 0], ds['X_train'][:, 1], c=ds['y_train'], cmap=cm_bright, edgecolors=\"k\")\n",
    "        # Plot the testing points\n",
    "        ax.scatter(\n",
    "            ds['X_test'][:, 0], ds['X_test'][:, 1], c=ds['y_test'], cmap=cm_bright, alpha=0.5, edgecolors=\"k\"\n",
    "        )\n",
    "        x_min, x_max = ds['X'][:, 0].min() - 0.5, ds['X'][:, 0].max() + 0.5\n",
    "        y_min, y_max = ds['X'][:, 1].min() - 0.5, ds['X'][:, 1].max() + 0.5\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "        for j, ker in enumerate(kernels):\n",
    "            base_alpha = 0.2 if show_support else 1.0\n",
    "            ax = plt.subplot(len(datasets), len(kernels)+1, i*(len(kernels)+1)+j+2)\n",
    "            score = models[i][j].score(ds['X_test'], ds['y_test'])\n",
    "            DecisionBoundaryDisplay.from_estimator(\n",
    "                models[i][j], ds['X'], cmap=cm, alpha=0.8, ax=ax, eps=0.5\n",
    "            )\n",
    "\n",
    "            # Plot the training points\n",
    "            ax.scatter(ds['X_train'][:, 0], ds['X_train'][:, 1], c=ds['y_train'], cmap=cm_bright, alpha=base_alpha, edgecolors=\"k\")\n",
    "            # Plot the testing points\n",
    "            ax.scatter(\n",
    "                ds['X_test'][:, 0], ds['X_test'][:, 1], c=ds['y_test'], cmap=cm_bright, alpha=0.5*base_alpha, edgecolors=\"k\"\n",
    "            )\n",
    "\n",
    "            if show_support:\n",
    "                # Support vectors\n",
    "                support_idxs = models[i][j].support_\n",
    "                support, support_y = ds['X_train'][support_idxs], ds['y_train'][support_idxs]\n",
    "                ax.scatter(\n",
    "                    support[:, 0], support[:, 1], c=support_y, cmap=cm_bright, edgecolors=\"k\"\n",
    "                )\n",
    "            ax.set_xlim(x_min, x_max)\n",
    "            ax.set_ylim(y_min, y_max)\n",
    "            ax.set_xticks(())\n",
    "            ax.set_yticks(())\n",
    "\n",
    "            if i == 0:\n",
    "                ax.set_title(ker + ' supports' if show_support else ker)\n",
    "            if not show_support:\n",
    "                ax.text(\n",
    "                    x_max - 0.3,\n",
    "                    y_min + 0.3,\n",
    "                    f'{score*100:.1f}%',\n",
    "                    size=15,\n",
    "                    horizontalalignment=\"right\",\n",
    "                    weight=\"bold\",\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11952ec-3b22-4967-8a83-ae12523fa361",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_decision_boundaries(datasets, kernels, models, show_support=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab204af-02e2-482d-9ae1-0658dc9bc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_decision_boundaries(datasets, kernels, models, show_support=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eee3db-d80e-41bb-a9c0-bd55150feab9",
   "metadata": {},
   "source": [
    "## CVXOPT SVM\n",
    "\n",
    "Next, we will implement a kernelized SVM using the cvxopt library. <span class=\"instruction\">Please complete the functions `get_qp_params`, `fit_bias`, and `decision_function` of `cvxopt_svm.py`</span>\n",
    "\n",
    "Please make sure your code works for any passed in kernel (i.e. any value of `kernel_params`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1764fb9e-db03-494d-9fca-57954361b296",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "Use the code below to (partially) check whether your code is correct. A complete check will be performed on the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476f177-d8ee-4d32-96af-aeca53f21264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gradient_check import rel_error\n",
    "from cvxopt_svm import get_qp_params, fit_bias, decision_function\n",
    "\n",
    "rng = np.random.default_rng(545)\n",
    "X = rng.normal(size=(5, 4))\n",
    "y = rng.normal(size=(5,))\n",
    "alpha = rng.binomial(5, 0.2, size=(5,))\n",
    "C = 1.0\n",
    "kernel_params = {'kernel': 'rbf', 'degree': 3, 'gamma': 0.2, 'coef0': 0.0}\n",
    "P, _, _, _, _, _ = get_qp_params(X, y, C, kernel_params)\n",
    "b = fit_bias(X, y, alpha, kernel_params)\n",
    "h = decision_function(X[:2], X, y, 545, alpha, kernel_params)\n",
    "\n",
    "P_sol = np.array([[ 0.45863879, -0.36760293, -0.09673795,  0.00553096, -0.01048321],\n",
    "       [-0.36760293,  1.09673362,  0.06906934, -0.13144294,  0.13565593],\n",
    "       [-0.09673795,  0.06906934,  0.46197662, -0.00232898,  0.01221352],\n",
    "       [ 0.00553096, -0.13144294, -0.00232898,  1.84930408, -0.23840086],\n",
    "       [-0.01048321,  0.13565593,  0.01221352, -0.23840086,  0.33240564]])\n",
    "\n",
    "b_sol = -0.4461256227781483\n",
    "h_sol = np.array([545.8439719 , 546.30869188])\n",
    "\n",
    "# Compare your output with ours. The error might be less than 1e-7.\n",
    "# As long as your error is small enough, your implementation should pass this test.\n",
    "print('Testing cvxopt functions:')\n",
    "print('difference: ', rel_error(P, P_sol))\n",
    "print('difference: ', rel_error(b, b_sol))\n",
    "print('difference: ', rel_error(h, h_sol))\n",
    "print()\n",
    "np.testing.assert_allclose(P, P_sol, atol=1e-6)\n",
    "np.testing.assert_allclose(b, b_sol, atol=1e-6)\n",
    "np.testing.assert_allclose(h, h_sol, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3bc95-b9e2-4a28-a6e7-fce194beb90d",
   "metadata": {},
   "source": [
    "## Test SVM\n",
    "\n",
    "Next, we want to test the performance of the cvxopt SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6595fa6f-cefe-4385-80a3-d942e0d548f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt_svm import CVXOPTSVC\n",
    "\n",
    "kernels = ['linear', 'poly', 'sigmoid', 'rbf']\n",
    "cvxopt_models = [[CVXOPTSVC(kernel=k, gamma=0.2).fit(ds['X_train'], ds['y_train']) for k in kernels] for ds in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b528f-247e-46da-b280-fa05b643bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "table = []\n",
    "for i, ds in enumerate(datasets):\n",
    "    row = []\n",
    "    for j, ker in enumerate(kernels):\n",
    "        pred = cvxopt_models[i][j].predict(ds['X_test'])\n",
    "\n",
    "        accuracy = (pred == ds['y_test']).mean()\n",
    "        row.append(accuracy)\n",
    "    table.append(row)\n",
    "\n",
    "header = '|  |' + ' | '.join(k for k in kernels) + ' |\\n'\n",
    "header += '|' + '--|'*(len(kernels)+1) + '\\n'\n",
    "rows = '\\n'.join(\n",
    "    f'| dataset {i} | ' + ' | '.join(f'{table[i][j]*100:.2f}' for j in range(len(kernels))) + ' |'\n",
    "    for i in range(len(datasets))\n",
    ")\n",
    "md('## CVXOPTSVM performance\\n' + header + rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b3812b-483e-44dc-9145-053ae9ec7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_decision_boundaries(datasets, kernels, cvxopt_models, show_support=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a14a58-7e41-44ed-94fd-6877999f8937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis_decision_boundaries(datasets, kernels, cvxopt_models, show_support=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b40ab0-0084-4d65-a026-53ee5759957b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
